{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1eedb574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c8021",
   "metadata": {},
   "source": [
    "# TOMORROW READ NOTES BELOW AND CONTINUE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7400e7eb",
   "metadata": {},
   "source": [
    "# I initially left some visualizations, to check that I did everything correct, so check that, and then delete some visulizations (i.e.) regression outputs and GATES comparison with True and Naive one!!!! UPD: I CHECKED IT, EVERYTHING IS FINE, Naive_estimated_GATES_comparison.png can be checked (got the same graph, like in the paper!!!!), ONLY VISUALIZATION NEEDED LATER ON ARE LEFT NOW!!!!!\n",
    "# Make the function with three parameters: model (if tuning, do it before putting model into this function), dataset, and the number of different data splits (onto A and B sample)!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1d90c",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning: do the optimization using the following targets (2 TARGETS), BUT IN PRACTICE, NO MATTER WHETHER SUCH HYPEROPTIMIZATION HELPS, DO HYPEROPTIMIZATION WHICH MINIMIZES MSE AND CHECK WHETHER HETEROGENEITY EXISTS AT ALL!!!!!! (IF NO HETEROGENEITY, NEW HYPEROPTIMIZATION IS EXPECTED TO 'BRING HETEROGENEITY' WHICH DOES NOT EXIST!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268aef4d",
   "metadata": {},
   "source": [
    "# Return of the function: \n",
    "## 1) GATES and CLAN tables with median values and median SCI (which will become 95% ones!!!) (or it still will be 97.5% if 1 datasplit!!!!) <br>  (IF 2 DATASPLITS, WHAT CONFIDENCE LEVEL IT WILL BE BY THE WAY?????)\n",
    "## 2a) If only 1 or several datasplits: return median 2 metrics (BLP and GATES one, which will be used as targets for the hyperparameter tuning, but try calculating this target at one split (faster), or median of several splits (less bias), BUT HYPERPARAMETER TUNING IS DONE USING CROSS-VALIDATION, SO MAYBE NO MUCH NEED TO USE DIFFERENT DATA SPLITS, DURING TUNING!!!\n",
    "## 2b) If more datasplits (i.e. 100): create 4 graphs after everything is done for each split!!! Histogram (or kde) of: 1, 2) Two target metrics for the quality of the model. 3, 4) mse, mae of S(X) relative to s_0(X) (1 obs - 1 datasplit). Also write descriptive statistics of these 4 variables!!!\n",
    "## 2* Make return of graphs of 2b) optional, as a parameter of function (i.e 'Extended' binary parameter)(make and return these graphs or not, since sometimes I may need 1 datasplit, not 100, so the graphs would be pointless in this case!!!)\n",
    "## * Also make optional parameter of whether to show the summary of BLP regression (needed to create DGPs, which should show the difference, i.e. beta_2 parameter significantly far away from 1)!!! \n",
    "## ** Also do three small supportive functions: The one which returns BLP regression only (to create needed DGPs faster!!!). And two functions which return needed targets (convinient functions for the hyperparameter tuning!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fce8c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting ggplot style for the graphs\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef1fc",
   "metadata": {},
   "source": [
    "# Some data generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f392dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "# empty df\n",
    "df = pd.DataFrame()\n",
    "# NUMBER OF OBSERVATIONS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
    "obs = 10000\n",
    "# explanatory variables: X\n",
    "df['x1'] = np.random.uniform(-1, 3, obs)\n",
    "df['x2'] = np.random.uniform(-6, 2, obs)\n",
    "df['x3'] = np.random.uniform(8, 14, obs)\n",
    "df['x4'] = np.random.uniform(2, 30, obs)\n",
    "df['x5'] = np.random.uniform(-8, 10, obs)\n",
    "eps = np.random.normal(0, 16, obs)\n",
    "eps1 = np.random.normal(0, 16, obs)\n",
    "# b(X) = Y(0)\n",
    "b_0 = 4 + 6*df.x1 + 8*df.x2 - 9*df.x1*df.x2 + 3 * np.log(df.x3) - df.x4**(1/3) * df.x3 + eps\n",
    "# propensity score: p(D = 1 | X), bounded from 0 and 1\n",
    "df['p'] = (8 + df.x1 + df.x2 + df.x3 * 0.5) / 32\n",
    "# s(X) = Y(1) - Y(0)\n",
    "df['s_0(X)'] = np.maximum(0, df.x1) - np.log(10 + df.x2) + np.minimum(0, df.x1 * df.x2) +\\\n",
    "               (df.x4-16)**2 + 6 * df.x3 + eps1\n",
    "#df['s_0(X)'] = 0\n",
    "# whether the treatment was assigned (D), given propensity score\n",
    "df['D'] = np.random.binomial(1, df.p)\n",
    "# CREATION OF Y:\n",
    "df['y'] = b_0 + df['s_0(X)'] * df.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c815090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>p</th>\n",
       "      <th>s_0(X)</th>\n",
       "      <th>D</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.173620</td>\n",
       "      <td>0.945756</td>\n",
       "      <td>13.215007</td>\n",
       "      <td>21.900172</td>\n",
       "      <td>-4.352087</td>\n",
       "      <td>0.522715</td>\n",
       "      <td>122.180856</td>\n",
       "      <td>1</td>\n",
       "      <td>101.264151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113478</td>\n",
       "      <td>1.952099</td>\n",
       "      <td>12.554939</td>\n",
       "      <td>5.891914</td>\n",
       "      <td>3.417984</td>\n",
       "      <td>0.510720</td>\n",
       "      <td>174.112055</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.246913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698070</td>\n",
       "      <td>1.510368</td>\n",
       "      <td>10.737484</td>\n",
       "      <td>23.936492</td>\n",
       "      <td>-0.982472</td>\n",
       "      <td>0.486787</td>\n",
       "      <td>91.193897</td>\n",
       "      <td>1</td>\n",
       "      <td>74.214096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.379105</td>\n",
       "      <td>-4.337320</td>\n",
       "      <td>8.360820</td>\n",
       "      <td>17.193009</td>\n",
       "      <td>7.172067</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>44.794767</td>\n",
       "      <td>0</td>\n",
       "      <td>46.031407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.981125</td>\n",
       "      <td>-0.274822</td>\n",
       "      <td>13.632987</td>\n",
       "      <td>26.541834</td>\n",
       "      <td>7.123235</td>\n",
       "      <td>0.423767</td>\n",
       "      <td>212.692860</td>\n",
       "      <td>1</td>\n",
       "      <td>156.119771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2         x3         x4        x5         p      s_0(X)  \\\n",
       "0  1.173620  0.945756  13.215007  21.900172 -4.352087  0.522715  122.180856   \n",
       "1  0.113478  1.952099  12.554939   5.891914  3.417984  0.510720  174.112055   \n",
       "2  0.698070  1.510368  10.737484  23.936492 -0.982472  0.486787   91.193897   \n",
       "3  2.379105 -4.337320   8.360820  17.193009  7.172067  0.319444   44.794767   \n",
       "4 -0.981125 -0.274822  13.632987  26.541834  7.123235  0.423767  212.692860   \n",
       "\n",
       "   D           y  \n",
       "0  1  101.264151  \n",
       "1  0  -25.246913  \n",
       "2  1   74.214096  \n",
       "3  0   46.031407  \n",
       "4  1  156.119771  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f0115e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790da042",
   "metadata": {},
   "source": [
    "## ML model!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ff05d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf0 = RandomForestRegressor()\n",
    "rf1 = RandomForestRegressor()\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elast0 = ElasticNet()\n",
    "elast1 = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ad7b0e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def term_paper_main_func(model0, model1, df, n_splits, show_BLP, extended):    \n",
    "    '''\n",
    "    The whole pipeline of the Chernozhukov paper, which will be used in my paper.\n",
    "    All aspects, by which the quality of heterogeneity ML estimation is observed: \n",
    "    from MAE, MSE to specific metrics (BLP, GATES, CLAN).\n",
    "    Note that column names of the df should be strongly specific (check first .ipynb notebooks!!!)\n",
    "    '''\n",
    "    # setting ggplot style for the graphs\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    ######## CALCULATION OF CRITICAL VALUE FOR THE SCI!!!!\n",
    "        # SCI taken from the Chernozhukov's 1st lecture: \n",
    "        ### https://ocw.mit.edu/courses/14-382-econometrics-spring-2017/c62d33e015c910b0d126bcc9344cf2c5_MIT14_382S17_lec1.pdf\n",
    "\n",
    "    # 500000 samples of Max (absolute value) out of 5 standard normals FOR CRITICAL VALUE!!!\n",
    "    k = np.max(np.abs(np.random.multivariate_normal(np.zeros(5), np.identity(5), 500000)), axis = 1)\n",
    "\n",
    "    # crit value for SCI!!!!!\n",
    "    if n_splits == 1: \n",
    "        # critical value for two-sided 95% interval!!!! (taking not 97.5%, since used np.abs above!!!!)\n",
    "        crit_val_simult = np.percentile(k, 95)\n",
    "    else:\n",
    "        # critical value for two-sided 97.5% interval!!!! (taking not 98.75%, since used np.abs above!!!!)\n",
    "        # DOING 97.5% SINCE AFTERWARDS I WILL DO MEDIANS AND INTERVAL WILL BECOME 95%!!!!\n",
    "        crit_val_simult = np.percentile(k, 97.5)\n",
    "\n",
    "    ### Automatic search for the covariates columns!!!\n",
    "    x_cols = []\n",
    "    for i in df.columns:\n",
    "        regexp = re.compile(r'^x\\d+$')\n",
    "        if regexp.search(i):\n",
    "            x_cols.append(i)\n",
    "\n",
    "    ######## Initializing arrays for tables and metrices of each split for \n",
    "                # further median SCI or histrograms and further descriptive statistics!!!!!!!!!!!!!!!!!!!!!\n",
    "    BLP_metrics = np.zeros(n_splits)\n",
    "    GATES_metrics = np.zeros(n_splits)\n",
    "    GATES_tables = np.zeros((n_splits, 5, 6))\n",
    "    CLAN_group1_tables = np.zeros((n_splits, len(x_cols) + 1, 6))\n",
    "    CLAN_group5_tables = np.zeros((n_splits, len(x_cols) + 1, 6))\n",
    "    CLAN_group5_minus_group1_tables = np.zeros((n_splits, len(x_cols) + 1, 6))\n",
    "    MAEs = np.zeros(n_splits)\n",
    "    MSEs = np.zeros(n_splits)\n",
    "\n",
    "    # iterating for different data splits!!!!\n",
    "    for split in tqdm(range(n_splits)):\n",
    "\n",
    "        ### Split the data onto 2 parts\n",
    "        obs = df.shape[0]\n",
    "        ind_A = random.sample(range(int(obs)), int(obs / 2))\n",
    "        ind_B = list(set(range(int(obs))).difference(set(ind_A)))\n",
    "        df_A = df.iloc[ind_A, :].copy()\n",
    "        df_B = df.iloc[ind_B, :].copy()\n",
    "\n",
    "        ###### ML Modelling\n",
    "        # B(X) (D = 0)\n",
    "        X_train0 = df_A[df_A['D'] == 0][x_cols]\n",
    "        y_train0 = df_A[df_A['D'] == 0]['y']\n",
    "        X_pred0 = df_B[x_cols]\n",
    "        # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "        scaler0 = MinMaxScaler()\n",
    "        scaler0.fit(X_train0)\n",
    "        model0.fit(scaler0.transform(X_train0), y_train0)\n",
    "        df_B['B(X)'] = model0.predict(scaler0.transform(X_pred0))\n",
    "\n",
    "        # D = 1\n",
    "        X_train1 = df_A[df_A['D'] == 1][x_cols]\n",
    "        y_train1 = df_A[df_A['D'] == 1]['y']\n",
    "        X_pred1 = df_B[x_cols]\n",
    "        # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "        scaler1 = MinMaxScaler()\n",
    "        scaler1.fit(X_train1)\n",
    "        model1.fit(scaler1.transform(X_train1), y_train1)\n",
    "        df_B['E(Y|D=1)'] = model1.predict(scaler1.transform(X_pred1))\n",
    "\n",
    "        # ML estimation of heterogeneity S(X) \n",
    "        df_B['S(X)'] = df_B['E(Y|D=1)'] - df_B['B(X)']\n",
    "\n",
    "\n",
    "        ######## I) BLP: page 11 of the paper (1st strategy)\n",
    "        \n",
    "        # creating missing variables for BLP estimation\n",
    "        df_B['const'] = 1\n",
    "        df_B['D_minus_p'] = df_B['D'] - df_B['p']\n",
    "        df_B['D_minus_p_times_S(X)_minus_ES'] = df_B['D_minus_p'] * (df_B['S(X)'] - np.mean(df_B['S(X)']))\n",
    "\n",
    "        vars_to_use_in_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']\n",
    "\n",
    "        ### Weighting variable for the WLS\n",
    "        df_B['omega(X)'] = 1 / df_B['p'] / (1 - df_B['p']) \n",
    "\n",
    "        ### Variables for the BLP WLS\n",
    "        Xs_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']\n",
    "\n",
    "        ########## BLP regression and beta_2 which is proportional to the quality of prediction of heterogeneity \n",
    "                     # if heterogeneity exists!!!!\n",
    "        model_BLP = sm.WLS(df_B['y'], df_B[Xs_BLP], weights = df_B['omega(X)'] ** 2).fit(cov_type='HC3')\n",
    "\n",
    "        # displaying BLP if specified!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        if show_BLP == True:\n",
    "            print('BLP regression summary, iteration: {}'.format(split))\n",
    "            display(model_BLP.summary())\n",
    "\n",
    "        ################### FIRST METRIC OF MODEL QUALITY FROM THE PAPER (FIRST TARGET IN HYPERPARAMETER TUNING)\n",
    "        Lambda_hat = model_BLP.params[-1] ** 2 * np.var(df_B['S(X)'])\n",
    "        BLP_metrics[split] = Lambda_hat\n",
    "\n",
    "\n",
    "        ## Creating group dummy variables: Split onto 5 equal-sized groups, based on S(X) \n",
    "                 #(1st group with lowest S(X), 5th group with highest S(X))\n",
    "        df_B = df_B.sort_values('S(X)')\n",
    "\n",
    "        for i in range(5):\n",
    "            name = 'Group_{}'.format(i + 1)\n",
    "            zero_vector = np.zeros(df_B.shape[0])\n",
    "            # needed quantile gets 1!!\n",
    "            start_index = int(round(i * df_B.shape[0] / 5))\n",
    "            end_index = int(round((i + 1) * df_B.shape[0] / 5))\n",
    "            zero_vector[start_index: end_index] = 1\n",
    "            df_B[name] = zero_vector\n",
    "\n",
    "        df_B = df_B.sort_index()\n",
    "\n",
    "        ## Creating variables for the GATES 1st strategy WLS\n",
    "        # non-weighted new vars\n",
    "        for i in range(5):\n",
    "            name = 'D_minus_p_Group_{}'.format(i + 1)\n",
    "            group_name = 'Group_{}'.format(i + 1)\n",
    "            df_B[name] = df_B['D_minus_p'] * df_B[group_name]\n",
    "\n",
    "        Xs_for_GATES = ['const', 'B(X)', 'D_minus_p_Group_1',\n",
    "               'D_minus_p_Group_2', 'D_minus_p_Group_3',\n",
    "               'D_minus_p_Group_4', 'D_minus_p_Group_5']\n",
    "\n",
    "        ##### Actual GATES WLS\n",
    "        model_GATES = sm.WLS(df_B['y'], df_B[Xs_for_GATES], weights = df_B['omega(X)']).fit(cov_type='HC3')\n",
    "\n",
    "        ################### SECOND METRIC OF MODEL QUALITY FROM THE PAPER (SECOND CANDIDATE OF TARGET IN HYPERPARAMETER TUNING)\n",
    "        # assuming that there will always be a partition onto 5 groups, \n",
    "            # SO TAKING LAST 5 PARAMETERS HERE IS ALWAYS CORRECT!!!!!!\n",
    "        Lambda_bar_hat = 0.2 * np.sum(model_GATES.params[-5:] ** 2)\n",
    "        GATES_metrics[split] = Lambda_bar_hat\n",
    "\n",
    "        ######### GATES CALCULATION\n",
    "        group_cols = ['Group_1', 'Group_2', 'Group_3', 'Group_4', 'Group_5']\n",
    "\n",
    "        Estimated_GATES = model_GATES.params[-5:]\n",
    "        True_GATES = [df_B[df_B[group_cols[i]] == 1]['s_0(X)'].mean() for i in range(5)]\n",
    "\n",
    "        #################### III) CLAN\n",
    "        #### Page 17 of the paper, just do GATES difference and other covariates difference\n",
    "\n",
    "        df_B_group1 = df_B[df_B['Group_1'] == 1]\n",
    "        df_B_group5 = df_B[df_B['Group_5'] == 1]\n",
    "        # leave only needed columns for CLAN, based on tables 4, 5, 6 from the paper!!!!\n",
    "        cols_for_CLAN = ['x1', 'x2', 'x3', 'x4', 'x5', 'D', 'y', 'p', 's_0(X)', 'B(X)',\n",
    "               'E(Y|D=1)', 'S(X)']\n",
    "\n",
    "        ########### a) Analysis of the GATES, SCI taken from the Chernozhukov's 1st lecture: \n",
    "        ### https://ocw.mit.edu/courses/14-382-econometrics-spring-2017/c62d33e015c910b0d126bcc9344cf2c5_MIT14_382S17_lec1.pdf\n",
    "\n",
    "        ##### Proceeding with simultaneous confidence intervals!!!\n",
    "        \n",
    "        # SE of coefs, and coefs themselves\n",
    "        EST_GATES = model_GATES.params[-5:]\n",
    "        SE_EST_GATES = model_GATES.bse[-5:]\n",
    "\n",
    "        # simult CI for the GATES in estimated groups!!!\n",
    "        simult_CI_L_EST_GATES = EST_GATES - crit_val_simult * SE_EST_GATES\n",
    "        simult_CI_U_EST_GATES = EST_GATES + crit_val_simult * SE_EST_GATES\n",
    "\n",
    "        #### Grouping by REAL treatment effect!!!: Split onto 5 equal-sized groups, \n",
    "            # based on s_0(X) (1st group with lowest s_0(X), 5th group with highest s_0(X))\n",
    "        df_B = df_B.sort_values('s_0(X)')\n",
    "\n",
    "        for i in range(5):\n",
    "            name = 'Group_{}_REAL'.format(i + 1)\n",
    "            zero_vector = np.zeros(df_B.shape[0])\n",
    "            # needed quantile gets 1!!\n",
    "            start_index = int(round(i * df_B.shape[0] / 5))\n",
    "            end_index = int(round((i + 1) * df_B.shape[0] / 5))\n",
    "            zero_vector[start_index: end_index] = 1\n",
    "            df_B[name] = zero_vector\n",
    "\n",
    "        df_B = df_B.sort_index()\n",
    "\n",
    "        ##### REAL GATES\n",
    "        REAL_GATES = np.zeros(5)\n",
    "        SE_REAL_GATES = np.zeros(5)\n",
    "        for num, i in enumerate(['Group_1_REAL', 'Group_2_REAL', 'Group_3_REAL', 'Group_4_REAL', 'Group_5_REAL']):\n",
    "            REAL_GATES[num] = df_B[df_B[i] == 1]['s_0(X)'].mean()\n",
    "            SE_REAL_GATES[num] = df_B[df_B[i] == 1]['s_0(X)'].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "\n",
    "\n",
    "        #### simult CI for the GATES in REAL groups!!!\n",
    "        simult_CI_L_REAL_GATES = REAL_GATES - crit_val_simult * SE_REAL_GATES\n",
    "        simult_CI_U_REAL_GATES = REAL_GATES + crit_val_simult * SE_REAL_GATES\n",
    "\n",
    "        ####### 97.5% SCI, GATES\n",
    "        GATES_table = pd.DataFrame({'Group': range(1, 6), 'GATES_estimated': EST_GATES, 'SCI_L_estimated': simult_CI_L_EST_GATES, \n",
    "                      'SCI_U_estimated': simult_CI_U_EST_GATES, 'GATES_real': REAL_GATES,\n",
    "                      'SCI_L_real': simult_CI_L_REAL_GATES, 'SCI_U_real': simult_CI_U_REAL_GATES}).set_index('Group')\n",
    "        GATES_tables[split] = GATES_table.to_numpy()\n",
    "\n",
    "        ####### 97.5% SCI everywhere below (AFTER MEDIAN IT WILL BE 95%!!!!\n",
    "\n",
    "        ####### CLAN Group 1\n",
    "\n",
    "        # to Add GATES params\n",
    "        CLAN_cols = ['GATES'] + x_cols\n",
    "        num_rows_CLAN = len(CLAN_cols) \n",
    "\n",
    "        G1_est = np.zeros(num_rows_CLAN)\n",
    "        SCI_L_G1_est = np.zeros(num_rows_CLAN)\n",
    "        SCI_U_G1_est = np.zeros(num_rows_CLAN)\n",
    "        G1_real = np.zeros(num_rows_CLAN)\n",
    "        SCI_L_G1_real = np.zeros(num_rows_CLAN)\n",
    "        SCI_U_G1_real = np.zeros(num_rows_CLAN)\n",
    "        # matrix with CLAN data\n",
    "        CLAN_data_G1 = np.zeros((num_rows_CLAN, 6))\n",
    "        # GATES\n",
    "        CLAN_data_G1[0] = GATES_table.iloc[0]\n",
    "        # Other vars (X), filling by column\n",
    "        for num, i in enumerate(['Group_1', 'Group_1_REAL']):\n",
    "            # point estimate\n",
    "            CLAN_data_G1[1:, num*3] = df_B[df_B[i] == 1][x_cols].mean()\n",
    "            # Lower SCI\n",
    "            CLAN_data_G1[1:, num*3 + 1] = df_B[df_B[i] == 1][x_cols].mean() -\\\n",
    "                                    crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "            # Upper SCI\n",
    "            CLAN_data_G1[1:, num*3 + 2] = df_B[df_B[i] == 1][x_cols].mean() +\\\n",
    "                                    crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "\n",
    "        CLAN_group1_tables[split] = CLAN_data_G1\n",
    "\n",
    "        ####### CLAN Group 5\n",
    "\n",
    "        # to Add GATES params\n",
    "        CLAN_cols = ['GATES'] + x_cols\n",
    "        num_rows_CLAN = len(CLAN_cols) \n",
    "\n",
    "        G5_est = np.zeros(num_rows_CLAN)\n",
    "        SCI_L_G5_est = np.zeros(num_rows_CLAN)\n",
    "        SCI_U_G5_est = np.zeros(num_rows_CLAN)\n",
    "        G5_real = np.zeros(num_rows_CLAN)\n",
    "        SCI_L_G5_real = np.zeros(num_rows_CLAN)\n",
    "        SCI_U_G5_real = np.zeros(num_rows_CLAN)\n",
    "        # matrix with CLAN data\n",
    "        CLAN_data_G5 = np.zeros((num_rows_CLAN, 6))\n",
    "        # GATES\n",
    "        CLAN_data_G5[0] = GATES_table.iloc[4]\n",
    "        # Other vars (X), filling by column\n",
    "        for num, i in enumerate(['Group_5', 'Group_5_REAL']):\n",
    "            # point estimate\n",
    "            CLAN_data_G5[1:, num*3] = df_B[df_B[i] == 1][x_cols].mean()\n",
    "            # Lower SCI\n",
    "            CLAN_data_G5[1:, num*3 + 1] = df_B[df_B[i] == 1][x_cols].mean() -\\\n",
    "                                    crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "            # Upper SCI\n",
    "            CLAN_data_G5[1:, num*3 + 2] = df_B[df_B[i] == 1][x_cols].mean() +\\\n",
    "                                    crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "\n",
    "        CLAN_group5_tables[split] = CLAN_data_G5\n",
    "\n",
    "        ######### Group 5 - Group 1 \n",
    "        ## IN SCI DIVIDING BY SQRT OF NUMBER OF GROUP 5 OBSERVATIONS, ASSUMING THAT THE NUMBER OF \n",
    "            # OBSERVATIONS IN FIRST AND FIFTH GROUP IS THE SAME!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "        # to Add GATES params\n",
    "        CLAN_cols = ['GATES'] + x_cols\n",
    "        num_rows_CLAN = len(CLAN_cols) \n",
    "\n",
    "        G5_minus_G1_est = np.zeros(num_rows_CLAN)\n",
    "        SCI_L_G5_minus_G1_est = np.zeros(num_rows_CLAN)\n",
    "        SCI_U_G5_minus_G1_est = np.zeros(num_rows_CLAN)\n",
    "        G5_minus_G1_real = np.zeros(num_rows_CLAN)\n",
    "        SCI_L_G5_minus_G1_real = np.zeros(num_rows_CLAN)\n",
    "        SCI_U_G5_minus_G1_real = np.zeros(num_rows_CLAN)\n",
    "        # matrix with CLAN data\n",
    "        CLAN_data_G5_minus_G1 = np.zeros((num_rows_CLAN, 6))\n",
    "        ## GATES (real and estimated simultaneously)\n",
    "        # point estimates\n",
    "        CLAN_data_G5_minus_G1[0, [0, 3]] = np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[0, [0, 3]])\n",
    "        SCI_radius_G5_minus_G1_GATES = np.sqrt((np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[4, [1, 4]])) ** 2 +\\\n",
    "                                               (np.array(GATES_table.iloc[0, [0, 3]]) - np.array(GATES_table.iloc[0, [1, 4]])) ** 2)\n",
    "        # SCI L\n",
    "        CLAN_data_G5_minus_G1[0, [1, 4]] = np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[0, [0, 3]]) -\\\n",
    "                                                SCI_radius_G5_minus_G1_GATES\n",
    "        # SCI U\n",
    "        CLAN_data_G5_minus_G1[0, [2, 5]] = np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[0, [0, 3]]) +\\\n",
    "                                                SCI_radius_G5_minus_G1_GATES\n",
    "\n",
    "        ## Other vars (X), filling by column\n",
    "        for num, i in enumerate([['Group_5', 'Group_1'], ['Group_5_REAL', 'Group_1_REAL']]):\n",
    "            G5_var = i[0]\n",
    "            G1_var = i[1]\n",
    "            # point estimate\n",
    "            CLAN_data_G5_minus_G1[1:, num*3] = df_B[df_B[G5_var] == 1][x_cols].mean() - df_B[df_B[G1_var] == 1][x_cols].mean()\n",
    "            # Lower SCI: DIVIDING BY SQRT OF NUMBER OF GROUP 5 OBSERVATIONS, ASSUMING THAT THE NUMBER OF OBSERVATIONS IN FIRST AND \n",
    "                # FIFTH GROUP IS THE SAME!!!!\n",
    "            CLAN_data_G5_minus_G1[1:, num*3 + 1] = df_B[df_B[G5_var] == 1][x_cols].mean() - df_B[df_B[G1_var] == 1][x_cols].mean() -\\\n",
    "                                    (df_B[df_B[G5_var] == 1][x_cols].var() + df_B[df_B[G1_var] == 1][x_cols].var()) ** 0.5 /\\\n",
    "                                    np.sqrt(df_B[df_B[G5_var] == 1].shape[0]) * crit_val_simult\n",
    "            # Upper SCI\n",
    "            CLAN_data_G5_minus_G1[1:, num*3 + 2] = df_B[df_B[G5_var] == 1][x_cols].mean() - df_B[df_B[G1_var] == 1][x_cols].mean() +\\\n",
    "                                    (df_B[df_B[G5_var] == 1][x_cols].var() + df_B[df_B[G1_var] == 1][x_cols].var()) ** 0.5 /\\\n",
    "                                    np.sqrt(df_B[df_B[G5_var] == 1].shape[0]) * crit_val_simult\n",
    "\n",
    "\n",
    "        CLAN_group5_minus_group1_tables[split] = CLAN_data_G5_minus_G1\n",
    "\n",
    "        ############## MSE and MAE of ML prediction of the treatment effect!!!\n",
    "        MSE = np.sum((df_B['s_0(X)'] - df_B['S(X)']) ** 2) / df_B.shape[0]\n",
    "        MAE = np.sum(np.abs(df_B['s_0(X)'] - df_B['S(X)'])) / df_B.shape[0]\n",
    "\n",
    "        MSEs[split] = MSE\n",
    "        MAEs[split] = MAE\n",
    "    \n",
    "    # Output depends on the number of splits (1 or more than 1)\n",
    "    if n_splits == 1:\n",
    "        df_metrics = pd.DataFrame({'BLP_metrics': np.round(BLP_metrics, 3), 'GATES_metrics': np.round(GATES_metrics, 3), \n",
    "                                  'MAEs': np.round(MAEs, 3), 'MSEs': np.round(MSEs, 3)})\n",
    "        print('Metrics table')\n",
    "        display(df_metrics)\n",
    "        df_GATES = pd.DataFrame(np.round(GATES_tables[0], 3))\n",
    "        df_GATES.columns = ['est', 'est_[0.025', '0.975]_est', 'real', 'real_[0.025', '0.975]_real']\n",
    "        df_GATES.index = ['G1', 'G2', 'G3', 'G4', 'G5']\n",
    "        print('GATES table')\n",
    "        display(df_GATES)\n",
    "        CLAN_dfs = []\n",
    "        for i in [CLAN_group1_tables, CLAN_group5_tables, CLAN_group5_minus_group1_tables]:\n",
    "            df0 = pd.DataFrame(np.round(i[0], 3))\n",
    "            df0.columns = ['est', 'est_[0.025', '0.975]_est', 'real', 'real_[0.025', '0.975]_real']\n",
    "            df0.index = ['GATES'] + x_cols\n",
    "            CLAN_dfs.append(df0)\n",
    "\n",
    "        df_CLAN_group1 = CLAN_dfs[0]\n",
    "        print('CLAN table group 1')\n",
    "        display(df_CLAN_group1)\n",
    "        df_CLAN_group5 = CLAN_dfs[1]\n",
    "        print('CLAN table group 5')\n",
    "        display(df_CLAN_group5)\n",
    "        df_CLAN_group5_minus_group1 = CLAN_dfs[2]\n",
    "        print('CLAN table group 5 minus group 1')\n",
    "        display(df_CLAN_group5_minus_group1)\n",
    "        \n",
    "        if extended == True:\n",
    "            print('EXTENDED OPTION IS AVAILABLE ONLY IF N_SPLITS IS BIGGER THAN 1')\n",
    "\n",
    "    else: \n",
    "        df_metrics = pd.DataFrame({'BLP_metrics': np.round(BLP_metrics, 3), 'GATES_metrics': np.round(GATES_metrics, 3), \n",
    "                                  'MAEs': np.round(MAEs, 3), 'MSEs': np.round(MSEs, 3)})\n",
    "        print('Metrics table')\n",
    "        display(df_metrics.describe())\n",
    "        df_GATES = pd.DataFrame(np.round(np.median(GATES_tables, axis = 0), 3))\n",
    "        df_GATES.columns = ['est', 'est_[0.025', '0.975]_est', 'real', 'real_[0.025', '0.975]_real']\n",
    "        df_GATES.index = ['G1', 'G2', 'G3', 'G4', 'G5']\n",
    "        print('GATES table')\n",
    "        display(df_GATES)\n",
    "        CLAN_dfs = []\n",
    "        for i in [CLAN_group1_tables, CLAN_group5_tables, CLAN_group5_minus_group1_tables]:\n",
    "            df0 = pd.DataFrame(np.round(np.median(i, axis = 0), 3))\n",
    "            df0.columns = ['est', 'est_[0.025', '0.975]_est', 'real', 'real_[0.025', '0.975]_real']\n",
    "            df0.index = ['GATES'] + x_cols\n",
    "            CLAN_dfs.append(df0)\n",
    "\n",
    "        df_CLAN_group1 = CLAN_dfs[0]\n",
    "        print('CLAN table group 1')\n",
    "        display(df_CLAN_group1)\n",
    "        df_CLAN_group5 = CLAN_dfs[1]\n",
    "        print('CLAN table group 5')\n",
    "        display(df_CLAN_group5)\n",
    "        df_CLAN_group5_minus_group1 = CLAN_dfs[2]\n",
    "        print('CLAN table group 5 minus group 1')\n",
    "        display(df_CLAN_group5_minus_group1)\n",
    "        \n",
    "        if extended == True: \n",
    "            Metrics_strings = ['BLP_metrics', 'GATES_metrics', 'MAEs', 'MSEs']\n",
    "            for num, metric in enumerate([BLP_metrics, GATES_metrics, MAEs, MSEs]): \n",
    "                bins_num = int(np.sqrt(n_splits))\n",
    "                plt.hist(metric, bins = bins_num)\n",
    "                plt.title(Metrics_strings[num], fontsize = 25)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "    return df_metrics, df_GATES, df_CLAN_group1, df_CLAN_group5, df_CLAN_group5_minus_group1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de7c573f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLP regression summary, iteration: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.677</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.676</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2750.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 Jun 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:34:06</td>     <th>  Log-Likelihood:    </th> <td> -26593.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>5.319e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4996</td>      <th>  BIC:               </th> <td>5.322e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>  108.7380</td> <td>    1.583</td> <td>   68.704</td> <td> 0.000</td> <td>  105.636</td> <td>  111.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B(X)</th>                          <td>    8.6717</td> <td>    0.190</td> <td>   45.592</td> <td> 0.000</td> <td>    8.299</td> <td>    9.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D_minus_p</th>                     <td>  128.2646</td> <td>    1.766</td> <td>   72.620</td> <td> 0.000</td> <td>  124.803</td> <td>  131.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D_minus_p_times_S(X)_minus_ES</th> <td>    5.3661</td> <td>    1.228</td> <td>    4.369</td> <td> 0.000</td> <td>    2.959</td> <td>    7.773</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>243.133</td> <th>  Durbin-Watson:     </th> <td>   1.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 440.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.377</td>  <th>  Prob(JB):          </th> <td>2.11e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.243</td>  <th>  Cond. No.          </th> <td>    20.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.677\n",
       "Model:                            WLS   Adj. R-squared:                  0.676\n",
       "Method:                 Least Squares   F-statistic:                     2750.\n",
       "Date:                Tue, 07 Jun 2022   Prob (F-statistic):               0.00\n",
       "Time:                        22:34:06   Log-Likelihood:                -26593.\n",
       "No. Observations:                5000   AIC:                         5.319e+04\n",
       "Df Residuals:                    4996   BIC:                         5.322e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                           108.7380      1.583     68.704      0.000     105.636     111.840\n",
       "B(X)                              8.6717      0.190     45.592      0.000       8.299       9.044\n",
       "D_minus_p                       128.2646      1.766     72.620      0.000     124.803     131.726\n",
       "D_minus_p_times_S(X)_minus_ES     5.3661      1.228      4.369      0.000       2.959       7.773\n",
       "==============================================================================\n",
       "Omnibus:                      243.133   Durbin-Watson:                   1.986\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              440.603\n",
       "Skew:                           0.377   Prob(JB):                     2.11e-96\n",
       "Kurtosis:                       4.243   Cond. No.                         20.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLP_metrics</th>\n",
       "      <th>GATES_metrics</th>\n",
       "      <th>MAEs</th>\n",
       "      <th>MSEs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.404</td>\n",
       "      <td>16687.486</td>\n",
       "      <td>52.447</td>\n",
       "      <td>3788.663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BLP_metrics  GATES_metrics    MAEs      MSEs\n",
       "0       60.404      16687.486  52.447  3788.663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATES table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est</th>\n",
       "      <th>est_[0.025</th>\n",
       "      <th>0.975]_est</th>\n",
       "      <th>real</th>\n",
       "      <th>real_[0.025</th>\n",
       "      <th>0.975]_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G1</th>\n",
       "      <td>116.581</td>\n",
       "      <td>107.318</td>\n",
       "      <td>125.843</td>\n",
       "      <td>55.711</td>\n",
       "      <td>54.713</td>\n",
       "      <td>56.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2</th>\n",
       "      <td>129.423</td>\n",
       "      <td>119.796</td>\n",
       "      <td>139.050</td>\n",
       "      <td>84.684</td>\n",
       "      <td>84.076</td>\n",
       "      <td>85.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3</th>\n",
       "      <td>125.419</td>\n",
       "      <td>115.974</td>\n",
       "      <td>134.863</td>\n",
       "      <td>115.128</td>\n",
       "      <td>114.273</td>\n",
       "      <td>115.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G4</th>\n",
       "      <td>131.106</td>\n",
       "      <td>120.553</td>\n",
       "      <td>141.660</td>\n",
       "      <td>161.214</td>\n",
       "      <td>159.890</td>\n",
       "      <td>162.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G5</th>\n",
       "      <td>142.047</td>\n",
       "      <td>132.051</td>\n",
       "      <td>152.043</td>\n",
       "      <td>225.611</td>\n",
       "      <td>223.721</td>\n",
       "      <td>227.502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        est  est_[0.025  0.975]_est     real  real_[0.025  0.975]_real\n",
       "G1  116.581     107.318     125.843   55.711       54.713       56.709\n",
       "G2  129.423     119.796     139.050   84.684       84.076       85.292\n",
       "G3  125.419     115.974     134.863  115.128      114.273      115.982\n",
       "G4  131.106     120.553     141.660  161.214      159.890      162.538\n",
       "G5  142.047     132.051     152.043  225.611      223.721      227.502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAN table group 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est</th>\n",
       "      <th>est_[0.025</th>\n",
       "      <th>0.975]_est</th>\n",
       "      <th>real</th>\n",
       "      <th>real_[0.025</th>\n",
       "      <th>0.975]_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GATES</th>\n",
       "      <td>116.581</td>\n",
       "      <td>107.318</td>\n",
       "      <td>125.843</td>\n",
       "      <td>55.711</td>\n",
       "      <td>54.713</td>\n",
       "      <td>56.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.860</td>\n",
       "      <td>1.791</td>\n",
       "      <td>1.929</td>\n",
       "      <td>1.091</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-1.021</td>\n",
       "      <td>-1.196</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>-2.147</td>\n",
       "      <td>-2.334</td>\n",
       "      <td>-1.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>9.239</td>\n",
       "      <td>9.163</td>\n",
       "      <td>9.315</td>\n",
       "      <td>10.254</td>\n",
       "      <td>10.127</td>\n",
       "      <td>10.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>12.196</td>\n",
       "      <td>11.622</td>\n",
       "      <td>12.771</td>\n",
       "      <td>15.875</td>\n",
       "      <td>15.645</td>\n",
       "      <td>16.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>1.317</td>\n",
       "      <td>0.897</td>\n",
       "      <td>1.737</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.606</td>\n",
       "      <td>1.450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           est  est_[0.025  0.975]_est    real  real_[0.025  0.975]_real\n",
       "GATES  116.581     107.318     125.843  55.711       54.713       56.709\n",
       "x1       1.860       1.791       1.929   1.091        0.996        1.186\n",
       "x2      -1.021      -1.196      -0.845  -2.147       -2.334       -1.961\n",
       "x3       9.239       9.163       9.315  10.254       10.127       10.381\n",
       "x4      12.196      11.622      12.771  15.875       15.645       16.105\n",
       "x5       1.317       0.897       1.737   1.028        0.606        1.450"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAN table group 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est</th>\n",
       "      <th>est_[0.025</th>\n",
       "      <th>0.975]_est</th>\n",
       "      <th>real</th>\n",
       "      <th>real_[0.025</th>\n",
       "      <th>0.975]_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GATES</th>\n",
       "      <td>142.047</td>\n",
       "      <td>132.051</td>\n",
       "      <td>152.043</td>\n",
       "      <td>225.611</td>\n",
       "      <td>223.721</td>\n",
       "      <td>227.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.187</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-3.042</td>\n",
       "      <td>-3.210</td>\n",
       "      <td>-2.874</td>\n",
       "      <td>-1.873</td>\n",
       "      <td>-2.061</td>\n",
       "      <td>-1.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>12.771</td>\n",
       "      <td>12.692</td>\n",
       "      <td>12.850</td>\n",
       "      <td>11.442</td>\n",
       "      <td>11.304</td>\n",
       "      <td>11.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>19.846</td>\n",
       "      <td>19.242</td>\n",
       "      <td>20.451</td>\n",
       "      <td>15.276</td>\n",
       "      <td>14.265</td>\n",
       "      <td>16.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.223</td>\n",
       "      <td>1.058</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           est  est_[0.025  0.975]_est     real  real_[0.025  0.975]_real\n",
       "GATES  142.047     132.051     152.043  225.611      223.721      227.502\n",
       "x1       0.187       0.115       0.259    0.891        0.796        0.986\n",
       "x2      -3.042      -3.210      -2.874   -1.873       -2.061       -1.686\n",
       "x3      12.771      12.692      12.850   11.442       11.304       11.579\n",
       "x4      19.846      19.242      20.451   15.276       14.265       16.288\n",
       "x5       0.640       0.223       1.058    1.070        0.651        1.490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAN table group 5 minus group 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est</th>\n",
       "      <th>est_[0.025</th>\n",
       "      <th>0.975]_est</th>\n",
       "      <th>real</th>\n",
       "      <th>real_[0.025</th>\n",
       "      <th>0.975]_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GATES</th>\n",
       "      <td>25.466</td>\n",
       "      <td>11.838</td>\n",
       "      <td>39.094</td>\n",
       "      <td>169.900</td>\n",
       "      <td>167.762</td>\n",
       "      <td>172.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>-1.673</td>\n",
       "      <td>-1.773</td>\n",
       "      <td>-1.573</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-2.022</td>\n",
       "      <td>-2.264</td>\n",
       "      <td>-1.779</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>3.532</td>\n",
       "      <td>3.422</td>\n",
       "      <td>3.642</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>7.650</td>\n",
       "      <td>6.816</td>\n",
       "      <td>8.484</td>\n",
       "      <td>-0.598</td>\n",
       "      <td>-1.636</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>-0.677</td>\n",
       "      <td>-1.269</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.553</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          est  est_[0.025  0.975]_est     real  real_[0.025  0.975]_real\n",
       "GATES  25.466      11.838      39.094  169.900      167.762      172.039\n",
       "x1     -1.673      -1.773      -1.573   -0.200       -0.334       -0.066\n",
       "x2     -2.022      -2.264      -1.779    0.274        0.010        0.539\n",
       "x3      3.532       3.422       3.642    1.188        1.000        1.375\n",
       "x4      7.650       6.816       8.484   -0.598       -1.636        0.439\n",
       "x5     -0.677      -1.269      -0.084    0.042       -0.553        0.637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_metrics, df_GATES, df_CLAN_group1, df_CLAN_group5, df_CLAN_group5_minus_group1 =\\\n",
    "            term_paper_main_func(model0 = elast0, model1 = elast1, \n",
    "                                 df = df.copy(), n_splits = 1, show_BLP = True, extended = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4af4b",
   "metadata": {},
   "source": [
    "# 2.6 seconds on one iteration (10000 data points, default rf, 5 covariates). Out of this time, 2.25 seconds is the ML estimation each iteration!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1170fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3839fed3",
   "metadata": {},
   "source": [
    "# Smaller functions, which I need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc215a4f",
   "metadata": {},
   "source": [
    "## 1) Coefficient which shows how accurate the ML estimation of heterogeneity is (if heterogeneity exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1720a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_2(df, model0, model1):\n",
    "    '''\n",
    "    Coefficient which shows how accurate the ML estimation of heterogeneity is (if heterogeneity exists)\n",
    "    '''\n",
    "    \n",
    "    ### Automatic search for the covariates columns!!!\n",
    "    x_cols = []\n",
    "    for i in df.columns:\n",
    "        regexp = re.compile(r'^x\\d+$')\n",
    "        if regexp.search(i):\n",
    "            x_cols.append(i)\n",
    "\n",
    "    ### Split the data onto 2 parts\n",
    "    obs = df.shape[0]\n",
    "    ind_A = random.sample(range(int(obs)), int(obs / 2))\n",
    "    ind_B = list(set(range(int(obs))).difference(set(ind_A)))\n",
    "    df_A = df.iloc[ind_A, :].copy()\n",
    "    df_B = df.iloc[ind_B, :].copy()\n",
    "\n",
    "    ###### ML Modelling\n",
    "    # B(X) (D = 0)\n",
    "    X_train0 = df_A[df_A['D'] == 0][x_cols]\n",
    "    y_train0 = df_A[df_A['D'] == 0]['y']\n",
    "    X_pred0 = df_B[x_cols]\n",
    "    # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "    scaler0 = MinMaxScaler()\n",
    "    scaler0.fit(X_train0)\n",
    "    model0.fit(scaler0.transform(X_train0), y_train0)\n",
    "    df_B['B(X)'] = model0.predict(scaler0.transform(X_pred0))\n",
    "\n",
    "    # D = 1\n",
    "    X_train1 = df_A[df_A['D'] == 1][x_cols]\n",
    "    y_train1 = df_A[df_A['D'] == 1]['y']\n",
    "    X_pred1 = df_B[x_cols]\n",
    "    # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "    scaler1 = MinMaxScaler()\n",
    "    scaler1.fit(X_train1)\n",
    "    model1.fit(scaler1.transform(X_train1), y_train1)\n",
    "    df_B['E(Y|D=1)'] = model1.predict(scaler1.transform(X_pred1))\n",
    "\n",
    "    # ML estimation of heterogeneity S(X) \n",
    "    df_B['S(X)'] = df_B['E(Y|D=1)'] - df_B['B(X)']\n",
    "\n",
    "\n",
    "    ######## I) BLP: page 11 of the paper (1st strategy)\n",
    "\n",
    "    # creating missing variables for BLP estimation\n",
    "    df_B['const'] = 1\n",
    "    df_B['D_minus_p'] = df_B['D'] - df_B['p']\n",
    "    df_B['D_minus_p_times_S(X)_minus_ES'] = df_B['D_minus_p'] * (df_B['S(X)'] - np.mean(df_B['S(X)']))\n",
    "\n",
    "    vars_to_use_in_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']\n",
    "\n",
    "    ### Weighting variable for the WLS\n",
    "    df_B['omega(X)'] = 1 / df_B['p'] / (1 - df_B['p']) \n",
    "\n",
    "    ### Variables for the BLP WLS\n",
    "    Xs_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']\n",
    "\n",
    "    ########## BLP regression and beta_2 which is proportional to the quality of prediction of heterogeneity \n",
    "                 # if heterogeneity exists!!!!\n",
    "    model_BLP = sm.WLS(df_B['y'], df_B[Xs_BLP], weights = df_B['omega(X)'] ** 2).fit(cov_type='HC3')\n",
    "    Beta_2 = model_BLP.params[-1] \n",
    "    \n",
    "    # Returning beta 2 parameter!!!\n",
    "    return Beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ddd4d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920323575795287"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_2(df.copy(), rf0, rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093acc3",
   "metadata": {},
   "source": [
    "## 2) Lambda hat: BLP metric of from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8dd0c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_hat(df, model0, model1):\n",
    "    '''\n",
    "    BLP metric from the paper\n",
    "    '''\n",
    "    \n",
    "    ### Automatic search for the covariates columns!!!\n",
    "    x_cols = []\n",
    "    for i in df.columns:\n",
    "        regexp = re.compile(r'^x\\d+$')\n",
    "        if regexp.search(i):\n",
    "            x_cols.append(i)\n",
    "\n",
    "    ### Split the data onto 2 parts\n",
    "    obs = df.shape[0]\n",
    "    ind_A = random.sample(range(int(obs)), int(obs / 2))\n",
    "    ind_B = list(set(range(int(obs))).difference(set(ind_A)))\n",
    "    df_A = df.iloc[ind_A, :].copy()\n",
    "    df_B = df.iloc[ind_B, :].copy()\n",
    "\n",
    "    ###### ML Modelling\n",
    "    # B(X) (D = 0)\n",
    "    X_train0 = df_A[df_A['D'] == 0][x_cols]\n",
    "    y_train0 = df_A[df_A['D'] == 0]['y']\n",
    "    X_pred0 = df_B[x_cols]\n",
    "    # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "    scaler0 = MinMaxScaler()\n",
    "    scaler0.fit(X_train0)\n",
    "    model0.fit(scaler0.transform(X_train0), y_train0)\n",
    "    df_B['B(X)'] = model0.predict(scaler0.transform(X_pred0))\n",
    "\n",
    "    # D = 1\n",
    "    X_train1 = df_A[df_A['D'] == 1][x_cols]\n",
    "    y_train1 = df_A[df_A['D'] == 1]['y']\n",
    "    X_pred1 = df_B[x_cols]\n",
    "    # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "    scaler1 = MinMaxScaler()\n",
    "    scaler1.fit(X_train1)\n",
    "    model1.fit(scaler1.transform(X_train1), y_train1)\n",
    "    df_B['E(Y|D=1)'] = model1.predict(scaler1.transform(X_pred1))\n",
    "\n",
    "    # ML estimation of heterogeneity S(X) \n",
    "    df_B['S(X)'] = df_B['E(Y|D=1)'] - df_B['B(X)']\n",
    "\n",
    "\n",
    "    ######## I) BLP: page 11 of the paper (1st strategy)\n",
    "\n",
    "    # creating missing variables for BLP estimation\n",
    "    df_B['const'] = 1\n",
    "    df_B['D_minus_p'] = df_B['D'] - df_B['p']\n",
    "    df_B['D_minus_p_times_S(X)_minus_ES'] = df_B['D_minus_p'] * (df_B['S(X)'] - np.mean(df_B['S(X)']))\n",
    "\n",
    "    vars_to_use_in_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']\n",
    "\n",
    "    ### Weighting variable for the WLS\n",
    "    df_B['omega(X)'] = 1 / df_B['p'] / (1 - df_B['p']) \n",
    "\n",
    "    ### Variables for the BLP WLS\n",
    "    Xs_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']\n",
    "\n",
    "    ########## BLP regression and beta_2 which is proportional to the quality of prediction of heterogeneity \n",
    "                 # if heterogeneity exists!!!!\n",
    "    model_BLP = sm.WLS(df_B['y'], df_B[Xs_BLP], weights = df_B['omega(X)'] ** 2).fit(cov_type='HC3')\n",
    "    Lambda_hat = model_BLP.params[-1] ** 2 * np.var(df_B['S(X)'])\n",
    "    \n",
    "    # returning lambda_hat\n",
    "    return Lambda_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee2ca21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3308.923187487998"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_hat(df.copy(), rf0, rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b3f41017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.0880627504319"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_hat(df.copy(), elast0, elast1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a686b3",
   "metadata": {},
   "source": [
    "## 3) Lambda bar hat: GATES metric of from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4133423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_bar_hat(df, model0, model1):\n",
    "    '''\n",
    "    GATES metric from the paper\n",
    "    '''\n",
    "    \n",
    "    ### Automatic search for the covariates columns!!!\n",
    "    x_cols = []\n",
    "    for i in df.columns:\n",
    "        regexp = re.compile(r'^x\\d+$')\n",
    "        if regexp.search(i):\n",
    "            x_cols.append(i)\n",
    "\n",
    "    ### Split the data onto 2 parts\n",
    "    obs = df.shape[0]\n",
    "    ind_A = random.sample(range(int(obs)), int(obs / 2))\n",
    "    ind_B = list(set(range(int(obs))).difference(set(ind_A)))\n",
    "    df_A = df.iloc[ind_A, :].copy()\n",
    "    df_B = df.iloc[ind_B, :].copy()\n",
    "\n",
    "    ###### ML Modelling\n",
    "    # B(X) (D = 0)\n",
    "    X_train0 = df_A[df_A['D'] == 0][x_cols]\n",
    "    y_train0 = df_A[df_A['D'] == 0]['y']\n",
    "    X_pred0 = df_B[x_cols]\n",
    "    # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "    scaler0 = MinMaxScaler()\n",
    "    scaler0.fit(X_train0)\n",
    "    model0.fit(scaler0.transform(X_train0), y_train0)\n",
    "    df_B['B(X)'] = model0.predict(scaler0.transform(X_pred0))\n",
    "\n",
    "    # D = 1\n",
    "    X_train1 = df_A[df_A['D'] == 1][x_cols]\n",
    "    y_train1 = df_A[df_A['D'] == 1]['y']\n",
    "    X_pred1 = df_B[x_cols]\n",
    "    # MinMaxSCALER!!!!! (as mentioned in paper)\n",
    "    scaler1 = MinMaxScaler()\n",
    "    scaler1.fit(X_train1)\n",
    "    model1.fit(scaler1.transform(X_train1), y_train1)\n",
    "    df_B['E(Y|D=1)'] = model1.predict(scaler1.transform(X_pred1))\n",
    "\n",
    "    # ML estimation of heterogeneity S(X) \n",
    "    df_B['S(X)'] = df_B['E(Y|D=1)'] - df_B['B(X)']\n",
    "    \n",
    "    # creating missing variables for GATES estimation\n",
    "    df_B['const'] = 1\n",
    "    df_B['D_minus_p'] = df_B['D'] - df_B['p']\n",
    "    \n",
    "    ### Weighting variable for the WLS\n",
    "    df_B['omega(X)'] = 1 / df_B['p'] / (1 - df_B['p']) \n",
    "\n",
    "    ## Creating group dummy variables: Split onto 5 equal-sized groups, based on S(X) \n",
    "                 #(1st group with lowest S(X), 5th group with highest S(X))\n",
    "    df_B = df_B.sort_values('S(X)')\n",
    "\n",
    "    for i in range(5):\n",
    "        name = 'Group_{}'.format(i + 1)\n",
    "        zero_vector = np.zeros(df_B.shape[0])\n",
    "        # needed quantile gets 1!!\n",
    "        start_index = int(round(i * df_B.shape[0] / 5))\n",
    "        end_index = int(round((i + 1) * df_B.shape[0] / 5))\n",
    "        zero_vector[start_index: end_index] = 1\n",
    "        df_B[name] = zero_vector\n",
    "\n",
    "    df_B = df_B.sort_index()\n",
    "\n",
    "    ## Creating variables for the GATES 1st strategy WLS\n",
    "    # non-weighted new vars\n",
    "    for i in range(5):\n",
    "        name = 'D_minus_p_Group_{}'.format(i + 1)\n",
    "        group_name = 'Group_{}'.format(i + 1)\n",
    "        df_B[name] = df_B['D_minus_p'] * df_B[group_name]\n",
    "\n",
    "    Xs_for_GATES = ['const', 'B(X)', 'D_minus_p_Group_1',\n",
    "           'D_minus_p_Group_2', 'D_minus_p_Group_3',\n",
    "           'D_minus_p_Group_4', 'D_minus_p_Group_5']\n",
    "\n",
    "    ##### Actual GATES WLS\n",
    "    model_GATES = sm.WLS(df_B['y'], df_B[Xs_for_GATES], weights = df_B['omega(X)']).fit(cov_type='HC3')\n",
    "\n",
    "    ################### SECOND METRIC OF MODEL QUALITY FROM THE PAPER (SECOND CANDIDATE OF TARGET IN HYPERPARAMETER TUNING)\n",
    "    # assuming that there will always be a partition onto 5 groups, \n",
    "        # SO TAKING LAST 5 PARAMETERS HERE IS ALWAYS CORRECT!!!!!!\n",
    "    Lambda_bar_hat = 0.2 * np.sum(model_GATES.params[-5:] ** 2)\n",
    "    \n",
    "    # returning lambda_hat\n",
    "    return Lambda_bar_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd32352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19593.34263207475"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_bar_hat(df.copy(), rf0, rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c7457968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16388.35579249895"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_bar_hat(df.copy(), elast0, elast1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f1ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
