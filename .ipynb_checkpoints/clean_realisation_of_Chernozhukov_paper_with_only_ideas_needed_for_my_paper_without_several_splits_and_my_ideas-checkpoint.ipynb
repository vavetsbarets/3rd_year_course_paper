{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1eedb574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c8021",
   "metadata": {},
   "source": [
    "# TOMORROW READ NOTES BELOW AND CONTINUE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7400e7eb",
   "metadata": {},
   "source": [
    "# I initially left some visualizations, to check that I did everything correct, so check that, and then delete some visulizations (i.e.) regression outputs and GATES comparison with True and Naive one!!!! UPD: I CHECKED IT, EVERYTHING IS FINE, Naive_estimated_GATES_comparison.png can be checked (got the same graph, like in the paper!!!!), ONLY VISUALIZATION NEEDED LATER ON ARE LEFT NOW!!!!!\n",
    "# Make the function with three parameters: model (if tuning, do it before putting model into this function), dataset, and the number of different data splits (onto A and B sample)!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1d90c",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning: do the optimization using the following targets (2 TARGETS), BUT IN PRACTICE, NO MATTER WHETHER SUCH HYPEROPTIMIZATION HELPS, DO HYPEROPTIMIZATION WHICH MINIMIZES MSE AND CHECK WHETHER HETEROGENEITY EXISTS AT ALL!!!!!! (IF NO HETEROGENEITY, NEW HYPEROPTIMIZATION IS EXPECTED TO 'BRING HETEROGENEITY' WHICH DOES NOT EXIST!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268aef4d",
   "metadata": {},
   "source": [
    "# Return of the function: \n",
    "## 1) GATES and CLAN tables with median values and median SCI (which will become 95% ones!!!) (or it still will be 97.5% if 1 datasplit!!!!) <br>  (IF 2 DATASPLITS, WHAT CONFIDENCE LEVEL IT WILL BE BY THE WAY?????)\n",
    "## 2a) If only 1 or several datasplits: return median 2 metrics (BLP and GATES one, which will be used as targets for the hyperparameter tuning, but try calculating this target at one split (faster), or median of several splits (less bias), BUT HYPERPARAMETER TUNING IS DONE USING CROSS-VALIDATION, SO MAYBE NO MUCH NEED TO USE DIFFERENT DATA SPLITS, DURING TUNING!!!\n",
    "## 2b) If more datasplits (i.e. 100): create 4 graphs after everything is done for each split!!! Histogram (or kde) of: 1, 2) Two target metrics for the quality of the model. 3, 4) mse, mae of S(X) relative to s_0(X) (1 obs - 1 datasplit). Also write descriptive statistics of these 4 variables!!!\n",
    "## 2* Make return of graphs of 2b) optional, as a parameter of function (i.e 'Extended' binary parameter)(make and return these graphs or not, since sometimes I may need 1 datasplit, not 100, so the graphs would be pointless in this case!!!)\n",
    "## * Also make optional parameter of whether to show the summary of BLP regression (needed to create DGPs, which should show the difference, i.e. beta_2 parameter significantly far away from 1)!!! \n",
    "## ** Also do three small supportive functions: The one which returns BLP regression only (to create needed DGPs faster!!!). And two functions which return needed targets (convinient functions for the hyperparameter tuning!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fce8c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting ggplot style for the graphs\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef1fc",
   "metadata": {},
   "source": [
    "# Some data generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f392dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "# empty df\n",
    "df = pd.DataFrame()\n",
    "# NUMBER OF OBSERVATIONS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
    "obs = 10000\n",
    "# explanatory variables: X\n",
    "df['x1'] = np.random.uniform(-1, 3, obs)\n",
    "df['x2'] = np.random.uniform(-6, 2, obs)\n",
    "df['x3'] = np.random.uniform(8, 14, obs)\n",
    "df['x4'] = np.random.uniform(2, 30, obs)\n",
    "df['x5'] = np.random.uniform(-8, 10, obs)\n",
    "eps = np.random.normal(0, 16, obs)\n",
    "eps1 = np.random.normal(0, 16, obs)\n",
    "# b(X) = Y(0)\n",
    "b_0 = 4 + 6*df.x1 + 8*df.x2 - 9*df.x1*df.x2 + 3 * np.log(df.x3) - df.x4**(1/3) * df.x3 + eps\n",
    "# propensity score: p(D = 1 | X), bounded from 0 and 1\n",
    "df['p'] = (8 + df.x1 + df.x2 + df.x3 * 0.5) / 32\n",
    "# s(X) = Y(1) - Y(0)\n",
    "df['s_0(X)'] = np.maximum(0, df.x1) - np.log(10 + df.x2) + np.minimum(0, df.x1 * df.x2) +\\\n",
    "               (df.x4-16)**2 + 6 * df.x3 + eps1\n",
    "#df['s_0(X)'] = 0\n",
    "# whether the treatment was assigned (D), given propensity score\n",
    "df['D'] = np.random.binomial(1, df.p)\n",
    "# CREATION OF Y:\n",
    "df['y'] = b_0 + df['s_0(X)'] * df.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c815090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>p</th>\n",
       "      <th>s_0(X)</th>\n",
       "      <th>D</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.173620</td>\n",
       "      <td>0.945756</td>\n",
       "      <td>13.215007</td>\n",
       "      <td>21.900172</td>\n",
       "      <td>-4.352087</td>\n",
       "      <td>0.522715</td>\n",
       "      <td>122.180856</td>\n",
       "      <td>1</td>\n",
       "      <td>101.264151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113478</td>\n",
       "      <td>1.952099</td>\n",
       "      <td>12.554939</td>\n",
       "      <td>5.891914</td>\n",
       "      <td>3.417984</td>\n",
       "      <td>0.510720</td>\n",
       "      <td>174.112055</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.246913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698070</td>\n",
       "      <td>1.510368</td>\n",
       "      <td>10.737484</td>\n",
       "      <td>23.936492</td>\n",
       "      <td>-0.982472</td>\n",
       "      <td>0.486787</td>\n",
       "      <td>91.193897</td>\n",
       "      <td>1</td>\n",
       "      <td>74.214096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.379105</td>\n",
       "      <td>-4.337320</td>\n",
       "      <td>8.360820</td>\n",
       "      <td>17.193009</td>\n",
       "      <td>7.172067</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>44.794767</td>\n",
       "      <td>0</td>\n",
       "      <td>46.031407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.981125</td>\n",
       "      <td>-0.274822</td>\n",
       "      <td>13.632987</td>\n",
       "      <td>26.541834</td>\n",
       "      <td>7.123235</td>\n",
       "      <td>0.423767</td>\n",
       "      <td>212.692860</td>\n",
       "      <td>1</td>\n",
       "      <td>156.119771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2         x3         x4        x5         p      s_0(X)  \\\n",
       "0  1.173620  0.945756  13.215007  21.900172 -4.352087  0.522715  122.180856   \n",
       "1  0.113478  1.952099  12.554939   5.891914  3.417984  0.510720  174.112055   \n",
       "2  0.698070  1.510368  10.737484  23.936492 -0.982472  0.486787   91.193897   \n",
       "3  2.379105 -4.337320   8.360820  17.193009  7.172067  0.319444   44.794767   \n",
       "4 -0.981125 -0.274822  13.632987  26.541834  7.123235  0.423767  212.692860   \n",
       "\n",
       "   D           y  \n",
       "0  1  101.264151  \n",
       "1  0  -25.246913  \n",
       "2  1   74.214096  \n",
       "3  0   46.031407  \n",
       "4  1  156.119771  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f0115e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790da042",
   "metadata": {},
   "source": [
    "## ML model!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff05d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572a414",
   "metadata": {},
   "source": [
    "### Split the data onto 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf41f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_A = random.sample(range(int(obs)), int(obs / 2))\n",
    "ind_B = list(set(range(int(obs))).difference(set(ind_A)))\n",
    "df_A = df.iloc[ind_A, :].copy()\n",
    "df_B = df.iloc[ind_B, :].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad46318",
   "metadata": {},
   "source": [
    "### Automatic search for the covariates columns!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7344c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', 'x2', 'x3', 'x4', 'x5']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = []\n",
    "for i in df.columns:\n",
    "    regexp = re.compile(r'^x\\d+$')\n",
    "    if regexp.search(i):\n",
    "        x_cols.append(i)\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49b184",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f904e8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>p</th>\n",
       "      <th>s_0(X)</th>\n",
       "      <th>D</th>\n",
       "      <th>y</th>\n",
       "      <th>B(X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113478</td>\n",
       "      <td>1.952099</td>\n",
       "      <td>12.554939</td>\n",
       "      <td>5.891914</td>\n",
       "      <td>3.417984</td>\n",
       "      <td>0.510720</td>\n",
       "      <td>174.112055</td>\n",
       "      <td>0</td>\n",
       "      <td>-25.246913</td>\n",
       "      <td>8.480289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698070</td>\n",
       "      <td>1.510368</td>\n",
       "      <td>10.737484</td>\n",
       "      <td>23.936492</td>\n",
       "      <td>-0.982472</td>\n",
       "      <td>0.486787</td>\n",
       "      <td>91.193897</td>\n",
       "      <td>1</td>\n",
       "      <td>74.214096</td>\n",
       "      <td>-10.940413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.981125</td>\n",
       "      <td>-0.274822</td>\n",
       "      <td>13.632987</td>\n",
       "      <td>26.541834</td>\n",
       "      <td>7.123235</td>\n",
       "      <td>0.423767</td>\n",
       "      <td>212.692860</td>\n",
       "      <td>1</td>\n",
       "      <td>156.119771</td>\n",
       "      <td>-33.375528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.513724</td>\n",
       "      <td>0.353463</td>\n",
       "      <td>9.564579</td>\n",
       "      <td>29.644230</td>\n",
       "      <td>7.910124</td>\n",
       "      <td>0.394438</td>\n",
       "      <td>228.275912</td>\n",
       "      <td>0</td>\n",
       "      <td>-28.042443</td>\n",
       "      <td>-13.614750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.303411</td>\n",
       "      <td>-2.453674</td>\n",
       "      <td>9.559623</td>\n",
       "      <td>9.219513</td>\n",
       "      <td>1.638712</td>\n",
       "      <td>0.394673</td>\n",
       "      <td>75.261756</td>\n",
       "      <td>0</td>\n",
       "      <td>18.614679</td>\n",
       "      <td>35.892834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2         x3         x4        x5         p      s_0(X)  \\\n",
       "1  0.113478  1.952099  12.554939   5.891914  3.417984  0.510720  174.112055   \n",
       "2  0.698070  1.510368  10.737484  23.936492 -0.982472  0.486787   91.193897   \n",
       "4 -0.981125 -0.274822  13.632987  26.541834  7.123235  0.423767  212.692860   \n",
       "5 -0.513724  0.353463   9.564579  29.644230  7.910124  0.394438  228.275912   \n",
       "7  2.303411 -2.453674   9.559623   9.219513  1.638712  0.394673   75.261756   \n",
       "\n",
       "   D           y       B(X)  \n",
       "1  0  -25.246913   8.480289  \n",
       "2  1   74.214096 -10.940413  \n",
       "4  1  156.119771 -33.375528  \n",
       "5  0  -28.042443 -13.614750  \n",
       "7  0   18.614679  35.892834  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D = 0\n",
    "X_train = df_A[df_A['D'] == 0][x_cols]\n",
    "y_train = df_A[df_A['D'] == 0]['y']\n",
    "X_pred = df_B[x_cols]\n",
    "rf.fit(X_train, y_train)\n",
    "df_B['B(X)'] = rf.predict(X_pred)\n",
    "df_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5dbb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = 1\n",
    "rf = RandomForestRegressor()\n",
    "X_train = df_A[df_A['D'] == 1][x_cols]\n",
    "y_train = df_A[df_A['D'] == 1]['y']\n",
    "X_pred = df_B[x_cols]\n",
    "rf.fit(X_train, y_train)\n",
    "df_B['E(Y|D=1)'] = rf.predict(X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b93ed5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B['S(X)'] = df_B['E(Y|D=1)'] - df_B['B(X)']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f408a",
   "metadata": {},
   "source": [
    "# I) BLP: page 11 of the paper (1st strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "775af7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating missing variables for BLP estimation\n",
    "df_B['const'] = 1\n",
    "df_B['D_minus_p'] = df_B['D'] - df_B['p']\n",
    "df_B['D_minus_p_times_S(X)_minus_ES'] = df_B['D_minus_p'] * (df_B['S(X)'] - np.mean(df_B['S(X)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efaea4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_use_in_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa07a50",
   "metadata": {},
   "source": [
    "### Weighting variable for the WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88c47179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B['omega(X)'] = 1 / df_B['p'] / (1 - df_B['p']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f1ff7",
   "metadata": {},
   "source": [
    "### Variables for the BLP WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "359d8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_BLP = ['const', 'B(X)', 'D_minus_p', 'D_minus_p_times_S(X)_minus_ES']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a56c58",
   "metadata": {},
   "source": [
    "## BLP regression and beta_2 which is proportional to the quality of prediction of heterogeneity if heterogeneity exists!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fd61f57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9429512798920092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.848</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.848</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7598.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Jun 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:25:41</td>     <th>  Log-Likelihood:    </th> <td> -24719.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>4.945e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4996</td>      <th>  BIC:               </th> <td>4.947e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC3</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>   49.0708</td> <td>    0.493</td> <td>   99.457</td> <td> 0.000</td> <td>   48.104</td> <td>   50.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B(X)</th>                          <td>    1.0598</td> <td>    0.012</td> <td>   85.680</td> <td> 0.000</td> <td>    1.036</td> <td>    1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D_minus_p</th>                     <td>  128.7390</td> <td>    1.076</td> <td>  119.601</td> <td> 0.000</td> <td>  126.629</td> <td>  130.849</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>D_minus_p_times_S(X)_minus_ES</th> <td>    0.9430</td> <td>    0.022</td> <td>   42.066</td> <td> 0.000</td> <td>    0.899</td> <td>    0.987</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>89.071</td> <th>  Durbin-Watson:     </th> <td>   2.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  94.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.317</td> <th>  Prob(JB):          </th> <td>3.26e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.224</td> <th>  Cond. No.          </th> <td>    87.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC3)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            WLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.848\n",
       "Model:                            WLS   Adj. R-squared:                  0.848\n",
       "Method:                 Least Squares   F-statistic:                     7598.\n",
       "Date:                Sun, 05 Jun 2022   Prob (F-statistic):               0.00\n",
       "Time:                        14:25:41   Log-Likelihood:                -24719.\n",
       "No. Observations:                5000   AIC:                         4.945e+04\n",
       "Df Residuals:                    4996   BIC:                         4.947e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:                  HC3                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                            49.0708      0.493     99.457      0.000      48.104      50.038\n",
       "B(X)                              1.0598      0.012     85.680      0.000       1.036       1.084\n",
       "D_minus_p                       128.7390      1.076    119.601      0.000     126.629     130.849\n",
       "D_minus_p_times_S(X)_minus_ES     0.9430      0.022     42.066      0.000       0.899       0.987\n",
       "==============================================================================\n",
       "Omnibus:                       89.071   Durbin-Watson:                   2.011\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               94.344\n",
       "Skew:                           0.317   Prob(JB):                     3.26e-21\n",
       "Kurtosis:                       3.224   Cond. No.                         87.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BLP = sm.WLS(df_B['y'], df_B[Xs_BLP], weights = df_B['omega(X)'] ** 2).fit(cov_type='HC3')\n",
    "beta_2 = model_BLP.params[-1]\n",
    "print(beta_2)\n",
    "model_BLP.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27ad88",
   "metadata": {},
   "source": [
    "# FIRST METRIC OF MODEL QUALITY FROM THE PAPER (FIRST TARGET IN HYPERPARAMETER TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cbb21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3288.609962847282\n"
     ]
    }
   ],
   "source": [
    "Lambda_hat = model_BLP.params[-1] ** 2 * np.var(df_B['S(X)'])\n",
    "print(Lambda_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfecf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18522014",
   "metadata": {},
   "source": [
    "## Creating group dummy variables: Split onto 5 equal-sized groups, based on S(X) (1st group with lowest S(X), 5th group with highest S(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28e0b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B = df_B.sort_values('S(X)')\n",
    "\n",
    "for i in range(5):\n",
    "    name = 'Group_{}'.format(i + 1)\n",
    "    zero_vector = np.zeros(df_B.shape[0])\n",
    "    # needed quantile gets 1!!\n",
    "    start_index = int(round(i * df_B.shape[0] / 5))\n",
    "    end_index = int(round((i + 1) * df_B.shape[0] / 5))\n",
    "    zero_vector[start_index: end_index] = 1\n",
    "    df_B[name] = zero_vector\n",
    "    \n",
    "df_B = df_B.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed833421",
   "metadata": {},
   "source": [
    "## Creating variables for the GATES 1st strategy WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd4eec83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x1', 'x2', 'x3', 'x4', 'x5', 'p', 's_0(X)', 'D', 'y', 'B(X)',\n",
       "       'E(Y|D=1)', 'S(X)', 'const', 'D_minus_p',\n",
       "       'D_minus_p_times_S(X)_minus_ES', 'omega(X)', 'Group_1', 'Group_2',\n",
       "       'Group_3', 'Group_4', 'Group_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3a51ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-weighted new vars\n",
    "for i in range(5):\n",
    "    name = 'D_minus_p_Group_{}'.format(i + 1)\n",
    "    group_name = 'Group_{}'.format(i + 1)\n",
    "    df_B[name] = df_B['D_minus_p'] * df_B[group_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3ee08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_for_GATES = ['const', 'B(X)', 'D_minus_p_Group_1',\n",
    "       'D_minus_p_Group_2', 'D_minus_p_Group_3',\n",
    "       'D_minus_p_Group_4', 'D_minus_p_Group_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da9903",
   "metadata": {},
   "source": [
    "## Actual GATES WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "514c1d76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_GATES = sm.WLS(df_B['y'], df_B[Xs_for_GATES], weights = df_B['omega(X)']).fit(cov_type='HC3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabd8a9",
   "metadata": {},
   "source": [
    "# SECOND METRIC OF MODEL QUALITY FROM THE PAPER (SECOND CANDIDATE OF TARGET IN HYPERPARAMETER TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b776370b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19944.205847745554"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming that there will always be a partition onto 5 groups, \n",
    "    # SO TAKING LAST 5 PARAMETERS HERE IS ALWAYS CORRECT!!!!!!\n",
    "Lambda_bar_hat = 0.2 * np.sum(model_GATES.params[-5:] ** 2)\n",
    "Lambda_bar_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c667c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = ['Group_1', 'Group_2', 'Group_3', 'Group_4', 'Group_5']\n",
    "\n",
    "Estimated_GATES = model_GATES.params[-5:]\n",
    "Naive_GATES = [df_B[df_B[group_cols[i]] == 1]['S(X)'].mean() for i in range(5)]\n",
    "True_GATES = [df_B[df_B[group_cols[i]] == 1]['s_0(X)'].mean() for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54387d26",
   "metadata": {},
   "source": [
    "# III) CLAN\n",
    "## Page 17 of the paper, just do GATES difference and other covariates difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6029c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B_group1 = df_B[df_B['Group_1'] == 1]\n",
    "df_B_group5 = df_B[df_B['Group_5'] == 1]\n",
    "# leave only needed columns for CLAN, based on tables 4, 5, 6 from the paper!!!!\n",
    "cols_for_CLAN = ['x1', 'x2', 'x3', 'x4', 'x5', 'D', 'y', 'p', 's_0(X)', 'B(X)',\n",
    "       'E(Y|D=1)', 'S(X)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563f2e1",
   "metadata": {},
   "source": [
    "## a) Analysis of the GATES, SCI taken from the Chernozhukov's 1st lecture: \n",
    "### https://ocw.mit.edu/courses/14-382-econometrics-spring-2017/c62d33e015c910b0d126bcc9344cf2c5_MIT14_382S17_lec1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d51f9",
   "metadata": {},
   "source": [
    "# Proceeding with simultaneous confidence intervals!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87067a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500000 samples of Max (absolute value) out of 5 standard normals FOR CRITICAL VALUE!!!\n",
    "k = np.max(np.abs(np.random.multivariate_normal(np.zeros(5), np.identity(5), 500000)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2bf5a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.798227062213706"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# critical value for two-sided 97.5% interval!!!! (taking not 98.75%, since used np.abs above!!!!)\n",
    "# DOING 97.5% SINCE AFTERWARDS I WILL DO MEDIANS AND INTERVAL WILL BECOME 95%!!!!\n",
    "crit_val_simult = np.percentile(k, 97.5)\n",
    "crit_val_simult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8581ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE of coefs, and coefs themselves\n",
    "EST_GATES = model_GATES.params[-5:]\n",
    "SE_EST_GATES = model_GATES.bse[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "941f1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simult CI for the GATES in estimated groups!!!\n",
    "simult_CI_L_EST_GATES = EST_GATES - crit_val_simult * SE_EST_GATES\n",
    "simult_CI_U_EST_GATES = EST_GATES + crit_val_simult * SE_EST_GATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf56964",
   "metadata": {},
   "source": [
    "### Grouping by REAL treatment effect!!!: Split onto 5 equal-sized groups, based on s_0(X) (1st group with lowest s_0(X), 5th group with highest s_0(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473f4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B = df_B.sort_values('s_0(X)')\n",
    "\n",
    "for i in range(5):\n",
    "    name = 'Group_{}_REAL'.format(i + 1)\n",
    "    zero_vector = np.zeros(df_B.shape[0])\n",
    "    # needed quantile gets 1!!\n",
    "    start_index = int(round(i * df_B.shape[0] / 5))\n",
    "    end_index = int(round((i + 1) * df_B.shape[0] / 5))\n",
    "    zero_vector[start_index: end_index] = 1\n",
    "    df_B[name] = zero_vector\n",
    "    \n",
    "df_B = df_B.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31687a7",
   "metadata": {},
   "source": [
    "### REAL GATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2553b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_GATES = np.zeros(5)\n",
    "SE_REAL_GATES = np.zeros(5)\n",
    "for num, i in enumerate(['Group_1_REAL', 'Group_2_REAL', 'Group_3_REAL', 'Group_4_REAL', 'Group_5_REAL']):\n",
    "    REAL_GATES[num] = df_B[df_B[i] == 1]['s_0(X)'].mean()\n",
    "    SE_REAL_GATES[num] = df_B[df_B[i] == 1]['s_0(X)'].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ea45ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simult CI for the GATES in REAL groups!!!\n",
    "simult_CI_L_REAL_GATES = REAL_GATES - crit_val_simult * SE_REAL_GATES\n",
    "simult_CI_U_REAL_GATES = REAL_GATES + crit_val_simult * SE_REAL_GATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc6aa4",
   "metadata": {},
   "source": [
    "## 97.5% SCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4db23c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GATES_estimated</th>\n",
       "      <th>SCI_L_estimated</th>\n",
       "      <th>SCI_U_estimated</th>\n",
       "      <th>GATES_real</th>\n",
       "      <th>SCI_L_real</th>\n",
       "      <th>SCI_U_real</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.224822</td>\n",
       "      <td>57.401847</td>\n",
       "      <td>71.047796</td>\n",
       "      <td>55.551432</td>\n",
       "      <td>54.487578</td>\n",
       "      <td>56.615287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.494100</td>\n",
       "      <td>77.023861</td>\n",
       "      <td>87.964339</td>\n",
       "      <td>84.771293</td>\n",
       "      <td>84.092935</td>\n",
       "      <td>85.449651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114.407179</td>\n",
       "      <td>109.286200</td>\n",
       "      <td>119.528159</td>\n",
       "      <td>115.805533</td>\n",
       "      <td>114.874304</td>\n",
       "      <td>116.736762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165.052840</td>\n",
       "      <td>158.902401</td>\n",
       "      <td>171.203278</td>\n",
       "      <td>162.118361</td>\n",
       "      <td>160.731254</td>\n",
       "      <td>163.505468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220.135146</td>\n",
       "      <td>210.780995</td>\n",
       "      <td>229.489297</td>\n",
       "      <td>225.864800</td>\n",
       "      <td>223.777269</td>\n",
       "      <td>227.952332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GATES_estimated  SCI_L_estimated  SCI_U_estimated  GATES_real  \\\n",
       "Group                                                                  \n",
       "1            64.224822        57.401847        71.047796   55.551432   \n",
       "2            82.494100        77.023861        87.964339   84.771293   \n",
       "3           114.407179       109.286200       119.528159  115.805533   \n",
       "4           165.052840       158.902401       171.203278  162.118361   \n",
       "5           220.135146       210.780995       229.489297  225.864800   \n",
       "\n",
       "       SCI_L_real  SCI_U_real  \n",
       "Group                          \n",
       "1       54.487578   56.615287  \n",
       "2       84.092935   85.449651  \n",
       "3      114.874304  116.736762  \n",
       "4      160.731254  163.505468  \n",
       "5      223.777269  227.952332  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GATES_table = pd.DataFrame({'Group': range(1, 6), 'GATES_estimated': EST_GATES, 'SCI_L_estimated': simult_CI_L_EST_GATES, \n",
    "              'SCI_U_estimated': simult_CI_U_EST_GATES, 'GATES_real': REAL_GATES,\n",
    "              'SCI_L_real': simult_CI_L_REAL_GATES, 'SCI_U_real': simult_CI_U_REAL_GATES}).set_index('Group')\n",
    "GATES_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db38e56",
   "metadata": {},
   "source": [
    "# 97.5% SCI everywhere below!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c61beb",
   "metadata": {},
   "source": [
    "## Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d30cd395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.224822</td>\n",
       "      <td>57.401847</td>\n",
       "      <td>71.047796</td>\n",
       "      <td>55.551432</td>\n",
       "      <td>54.487578</td>\n",
       "      <td>56.615287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.135512</td>\n",
       "      <td>1.031027</td>\n",
       "      <td>1.239998</td>\n",
       "      <td>1.033759</td>\n",
       "      <td>0.929112</td>\n",
       "      <td>1.138405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.052534</td>\n",
       "      <td>-2.249804</td>\n",
       "      <td>-1.855264</td>\n",
       "      <td>-2.126684</td>\n",
       "      <td>-2.327169</td>\n",
       "      <td>-1.926199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.160634</td>\n",
       "      <td>10.026101</td>\n",
       "      <td>10.295168</td>\n",
       "      <td>10.301688</td>\n",
       "      <td>10.159451</td>\n",
       "      <td>10.443924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.958410</td>\n",
       "      <td>15.709551</td>\n",
       "      <td>16.207269</td>\n",
       "      <td>15.894480</td>\n",
       "      <td>15.645226</td>\n",
       "      <td>16.143734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.248322</td>\n",
       "      <td>0.782061</td>\n",
       "      <td>1.714582</td>\n",
       "      <td>1.034053</td>\n",
       "      <td>0.577054</td>\n",
       "      <td>1.491052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5\n",
       "0  64.224822  57.401847  71.047796  55.551432  54.487578  56.615287\n",
       "1   1.135512   1.031027   1.239998   1.033759   0.929112   1.138405\n",
       "2  -2.052534  -2.249804  -1.855264  -2.126684  -2.327169  -1.926199\n",
       "3  10.160634  10.026101  10.295168  10.301688  10.159451  10.443924\n",
       "4  15.958410  15.709551  16.207269  15.894480  15.645226  16.143734\n",
       "5   1.248322   0.782061   1.714582   1.034053   0.577054   1.491052"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to Add GATES params\n",
    "CLAN_cols = ['GATES'] + x_cols\n",
    "num_rows_CLAN = len(CLAN_cols) \n",
    "\n",
    "G1_est = np.zeros(num_rows_CLAN)\n",
    "SCI_L_G1_est = np.zeros(num_rows_CLAN)\n",
    "SCI_U_G1_est = np.zeros(num_rows_CLAN)\n",
    "G1_real = np.zeros(num_rows_CLAN)\n",
    "SCI_L_G1_real = np.zeros(num_rows_CLAN)\n",
    "SCI_U_G1_real = np.zeros(num_rows_CLAN)\n",
    "# matrix with CLAN data\n",
    "CLAN_data_G1 = np.zeros((num_rows_CLAN, 6))\n",
    "# GATES\n",
    "CLAN_data_G1[0] = GATES_table.iloc[0]\n",
    "# Other vars (X), filling by column\n",
    "for num, i in enumerate(['Group_1', 'Group_1_REAL']):\n",
    "    # point estimate\n",
    "    CLAN_data_G1[1:, num*3] = df_B[df_B[i] == 1][x_cols].mean()\n",
    "    # Lower SCI\n",
    "    CLAN_data_G1[1:, num*3 + 1] = df_B[df_B[i] == 1][x_cols].mean() -\\\n",
    "                            crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "    # Upper SCI\n",
    "    CLAN_data_G1[1:, num*3 + 2] = df_B[df_B[i] == 1][x_cols].mean() +\\\n",
    "                            crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "\n",
    "\n",
    "pd.DataFrame(CLAN_data_G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fb935",
   "metadata": {},
   "source": [
    "## Group 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f7301a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.135146</td>\n",
       "      <td>210.780995</td>\n",
       "      <td>229.489297</td>\n",
       "      <td>225.864800</td>\n",
       "      <td>223.777269</td>\n",
       "      <td>227.952332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.839687</td>\n",
       "      <td>0.738757</td>\n",
       "      <td>0.940617</td>\n",
       "      <td>0.912769</td>\n",
       "      <td>0.810039</td>\n",
       "      <td>1.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.986917</td>\n",
       "      <td>-2.192005</td>\n",
       "      <td>-1.781829</td>\n",
       "      <td>-1.938307</td>\n",
       "      <td>-2.142331</td>\n",
       "      <td>-1.734283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.220309</td>\n",
       "      <td>11.066951</td>\n",
       "      <td>11.373667</td>\n",
       "      <td>11.329557</td>\n",
       "      <td>11.176812</td>\n",
       "      <td>11.482303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.613347</td>\n",
       "      <td>14.499028</td>\n",
       "      <td>16.727666</td>\n",
       "      <td>15.970532</td>\n",
       "      <td>14.860117</td>\n",
       "      <td>17.080947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.890815</td>\n",
       "      <td>0.428306</td>\n",
       "      <td>1.353324</td>\n",
       "      <td>1.019321</td>\n",
       "      <td>0.557491</td>\n",
       "      <td>1.481151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5\n",
       "0  220.135146  210.780995  229.489297  225.864800  223.777269  227.952332\n",
       "1    0.839687    0.738757    0.940617    0.912769    0.810039    1.015500\n",
       "2   -1.986917   -2.192005   -1.781829   -1.938307   -2.142331   -1.734283\n",
       "3   11.220309   11.066951   11.373667   11.329557   11.176812   11.482303\n",
       "4   15.613347   14.499028   16.727666   15.970532   14.860117   17.080947\n",
       "5    0.890815    0.428306    1.353324    1.019321    0.557491    1.481151"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to Add GATES params\n",
    "CLAN_cols = ['GATES'] + x_cols\n",
    "num_rows_CLAN = len(CLAN_cols) \n",
    "\n",
    "G5_est = np.zeros(num_rows_CLAN)\n",
    "SCI_L_G5_est = np.zeros(num_rows_CLAN)\n",
    "SCI_U_G5_est = np.zeros(num_rows_CLAN)\n",
    "G5_real = np.zeros(num_rows_CLAN)\n",
    "SCI_L_G5_real = np.zeros(num_rows_CLAN)\n",
    "SCI_U_G5_real = np.zeros(num_rows_CLAN)\n",
    "# matrix with CLAN data\n",
    "CLAN_data_G5 = np.zeros((num_rows_CLAN, 6))\n",
    "# GATES\n",
    "CLAN_data_G5[0] = GATES_table.iloc[4]\n",
    "# Other vars (X), filling by column\n",
    "for num, i in enumerate(['Group_5', 'Group_5_REAL']):\n",
    "    # point estimate\n",
    "    CLAN_data_G5[1:, num*3] = df_B[df_B[i] == 1][x_cols].mean()\n",
    "    # Lower SCI\n",
    "    CLAN_data_G5[1:, num*3 + 1] = df_B[df_B[i] == 1][x_cols].mean() -\\\n",
    "                            crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "    # Upper SCI\n",
    "    CLAN_data_G5[1:, num*3 + 2] = df_B[df_B[i] == 1][x_cols].mean() +\\\n",
    "                            crit_val_simult * df_B[df_B[i] == 1][x_cols].std() / np.sqrt(df_B[df_B[i] == 1].shape[0])\n",
    "\n",
    "\n",
    "pd.DataFrame(CLAN_data_G5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda4159",
   "metadata": {},
   "source": [
    "## Group 5 - Group 1 \n",
    "## IN SCI DIVIDING BY SQRT OF NUMBER OF GROUP 5 OBSERVATIONS, ASSUMING THAT THE NUMBER OF OBSERVATIONS IN FIRST AND FIFTH GROUP IS THE SAME!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f1d7ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.910324</td>\n",
       "      <td>144.332193</td>\n",
       "      <td>167.488456</td>\n",
       "      <td>170.313368</td>\n",
       "      <td>167.970384</td>\n",
       "      <td>172.656352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.295825</td>\n",
       "      <td>-0.441097</td>\n",
       "      <td>-0.150553</td>\n",
       "      <td>-0.120989</td>\n",
       "      <td>-0.267633</td>\n",
       "      <td>0.025654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065617</td>\n",
       "      <td>-0.218947</td>\n",
       "      <td>0.350180</td>\n",
       "      <td>0.188377</td>\n",
       "      <td>-0.097665</td>\n",
       "      <td>0.474419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.059675</td>\n",
       "      <td>0.855670</td>\n",
       "      <td>1.263679</td>\n",
       "      <td>1.027870</td>\n",
       "      <td>0.819154</td>\n",
       "      <td>1.236586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.345063</td>\n",
       "      <td>-1.486833</td>\n",
       "      <td>0.796706</td>\n",
       "      <td>0.076052</td>\n",
       "      <td>-1.061995</td>\n",
       "      <td>1.214098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.357507</td>\n",
       "      <td>-1.014251</td>\n",
       "      <td>0.299238</td>\n",
       "      <td>-0.014732</td>\n",
       "      <td>-0.664451</td>\n",
       "      <td>0.634987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5\n",
       "0  155.910324  144.332193  167.488456  170.313368  167.970384  172.656352\n",
       "1   -0.295825   -0.441097   -0.150553   -0.120989   -0.267633    0.025654\n",
       "2    0.065617   -0.218947    0.350180    0.188377   -0.097665    0.474419\n",
       "3    1.059675    0.855670    1.263679    1.027870    0.819154    1.236586\n",
       "4   -0.345063   -1.486833    0.796706    0.076052   -1.061995    1.214098\n",
       "5   -0.357507   -1.014251    0.299238   -0.014732   -0.664451    0.634987"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to Add GATES params\n",
    "CLAN_cols = ['GATES'] + x_cols\n",
    "num_rows_CLAN = len(CLAN_cols) \n",
    "\n",
    "G5_minus_G1_est = np.zeros(num_rows_CLAN)\n",
    "SCI_L_G5_minus_G1_est = np.zeros(num_rows_CLAN)\n",
    "SCI_U_G5_minus_G1_est = np.zeros(num_rows_CLAN)\n",
    "G5_minus_G1_real = np.zeros(num_rows_CLAN)\n",
    "SCI_L_G5_minus_G1_real = np.zeros(num_rows_CLAN)\n",
    "SCI_U_G5_minus_G1_real = np.zeros(num_rows_CLAN)\n",
    "# matrix with CLAN data\n",
    "CLAN_data_G5_minus_G1 = np.zeros((num_rows_CLAN, 6))\n",
    "## GATES (real and estimated simultaneously)\n",
    "# point estimates\n",
    "CLAN_data_G5_minus_G1[0, [0, 3]] = np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[0, [0, 3]])\n",
    "SCI_radius_G5_minus_G1_GATES = np.sqrt((np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[4, [1, 4]])) ** 2 +\\\n",
    "                                       (np.array(GATES_table.iloc[0, [0, 3]]) - np.array(GATES_table.iloc[0, [1, 4]])) ** 2)\n",
    "# SCI L\n",
    "CLAN_data_G5_minus_G1[0, [1, 4]] = np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[0, [0, 3]]) -\\\n",
    "                                        SCI_radius_G5_minus_G1_GATES\n",
    "# SCI U\n",
    "CLAN_data_G5_minus_G1[0, [2, 5]] = np.array(GATES_table.iloc[4, [0, 3]]) - np.array(GATES_table.iloc[0, [0, 3]]) +\\\n",
    "                                        SCI_radius_G5_minus_G1_GATES\n",
    "\n",
    "## Other vars (X), filling by column\n",
    "for num, i in enumerate([['Group_5', 'Group_1'], ['Group_5_REAL', 'Group_1_REAL']]):\n",
    "    G5_var = i[0]\n",
    "    G1_var = i[1]\n",
    "    # point estimate\n",
    "    CLAN_data_G5_minus_G1[1:, num*3] = df_B[df_B[G5_var] == 1][x_cols].mean() - df_B[df_B[G1_var] == 1][x_cols].mean()\n",
    "    # Lower SCI: DIVIDING BY SQRT OF NUMBER OF GROUP 5 OBSERVATIONS, ASSUMING THAT THE NUMBER OF OBSERVATIONS IN FIRST AND \n",
    "        # FIFTH GROUP IS THE SAME!!!!\n",
    "    CLAN_data_G5_minus_G1[1:, num*3 + 1] = df_B[df_B[G5_var] == 1][x_cols].mean() - df_B[df_B[G1_var] == 1][x_cols].mean() -\\\n",
    "                            (df_B[df_B[G5_var] == 1][x_cols].var() + df_B[df_B[G1_var] == 1][x_cols].var()) ** 0.5 /\\\n",
    "                            np.sqrt(df_B[df_B[G5_var] == 1].shape[0]) * crit_val_simult\n",
    "    # Upper SCI\n",
    "    CLAN_data_G5_minus_G1[1:, num*3 + 2] = df_B[df_B[G5_var] == 1][x_cols].mean() - df_B[df_B[G1_var] == 1][x_cols].mean() +\\\n",
    "                            (df_B[df_B[G5_var] == 1][x_cols].var() + df_B[df_B[G1_var] == 1][x_cols].var()) ** 0.5 /\\\n",
    "                            np.sqrt(df_B[df_B[G5_var] == 1].shape[0]) * crit_val_simult\n",
    "\n",
    "\n",
    "pd.DataFrame(CLAN_data_G5_minus_G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92862f1",
   "metadata": {},
   "source": [
    "## MSE and MAE of ML prediction of the treatment effect!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f04409d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433.20434582342114 16.392727722094197\n"
     ]
    }
   ],
   "source": [
    "MSE = np.sum((df_B['s_0(X)'] - df_B['S(X)']) ** 2) / df_B.shape[0]\n",
    "MAE = np.sum(np.abs(df_B['s_0(X)'] - df_B['S(X)'])) / df_B.shape[0]\n",
    "print(MSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489269e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
